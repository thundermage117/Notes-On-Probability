\documentclass{article}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}

\begin{document}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\tableofcontents
\newpage

\section{Probability Space}
There are often various approaches to probability each with its own advantages
and disadvantages.

Experiment is a procedure that can be infinitely repeated and has a
well-defined set of possible outcomes, known as the sample space.

The observation/result of the experiment are termed as outcomes.

\subsection{Classical Approach}
        Probability of an event $E$ is defined to be: $$P(E)=\frac{\text{Number of outcomes in }E}{\text{Total number of outcomes}}$$
         Some examples are tossing a coin or rolling a die.
         Disadvantages:
         \begin{itemize}
             \item Unable to model biases. It says nothing about cases where no
             physical symmetry exists.
             \item Doesn't deal with cases where total outcomes are infinite.
         \end{itemize}

         \subsection{Frequentist Approach}
         Also known as the relative frequency approach or frequentism. It defines
         an event's probability as the limit of its relative frequency in many
         trials.

         Probability is defined to be:
         $$ P(E)=\lim_{n \to \infty} \frac{n_E}{n}$$
         where an experiment is conducted $n$ times and event $E$ occurs $n_E$
         times.
         Disadvantages:
         \begin{itemize}
             \item It isn't efficient to conduct an experiment multiple times
             just to find the probability of an event occuring.
             \item It is unable to deal with subjective belief. Eg: Suppose a
             cricket expert says there is a $50\%$ of RCB winning the IPL this
             year. It doesn't mean that the RCB has won half the titles in the
             past.
         \end{itemize}
%
         \subsection{Axiomatic Approach}

         \subsubsection{Probability Space}

The triple ($S$, $F$, $P$) is referred to as a probability space where:
\begin{itemize}
    \item $S$ : Sample space, set of all possible outcomes of the experiment.
    \item $F$ : Event Space, subset of the sample space
    \item $P$ : Probability Measure
\end{itemize}
\subsubsection{Sample Space}

$S$ can either be finite or countably infinite or uncountably infinite.
%28/05

Examples for S:
\begin{itemize}
        \item Finite Sample Space: Single coin toss $ S=\{H,T\} $ and two coin tosses $ S=\{HH,HT,TT,TH\} $.
        \item Countably Infinite Sample Space: Keep tossing a coin till you get a head $ S=\{H,TH,TTH...\}$.
        \item Uncountably Infinite Sample Space: We have a circular dart board and we are measuring the angle at which a dart hits the board. $S=[0,2\pi]$
\end{itemize}

\subsection{Event Space}
Collection of events is called an event space, there are some properties to be satisified such as:
it has to be a ``Sigma Field''.

\subsubsection{Sigma Field}
A sigma field (or sigma algebra) F is a collection of subsets of S which satisfies the following properties:
\begin{itemize}
    \item $S \in F$
    \item If $E \in F$, then $E^C \in F$
    \item If $E_1,E_2,E_3 \cdots \in F $, then $\bigcup_{i=1}^{\infty} E_i \in F$
\end{itemize}

\subsubsection{Examples for Event Space}
\begin{itemize}
    \item Smallest possible event space:
    $$ F =\{ \phi,S\} $$
    \item Next non-trivial event space:
    $$ F=\{ \phi,E ,E^c ,S\}$$
    \item If $E_1 \in F$ and $E_2 \in F$, then $E_1 \cap E_2 \in F$ (Proof in 1.4.3)
    \item For S=$\{1,2,3,4,5,6\}$ , $E_1 =\{1,2\}$ and $E_2=\{3,4\}$. The smallest event space containing $E_1$ and $E_2$ is:
    $$ F=\{\phi , S, E_1 , E_{1}^{C},E_2 , E_{2}^{C},E_1 \cup E_2 , (E_{1} \cup E_{2})^{C}\}$$
\end{itemize}

\subsubsection{Proposition 1}
A$_1$, A$_2$, A$_3$,....A$_n$ $\in$ $F$, then $\bigcap\limits_{i=1}^n$A$_i$ $\in$ $F$.

\begin{proof}
    If A$_1$, A$_2$, A$_3$,....A$_n$ $\in$ $F$, then A$_1^c$, A$_2^c$, A$_3^c$,....A$_n^c$ $\in$ $F$ and $\bigcup\limits_{i=1}^n$A$_i^c$ $\in$ $F$. Then by property 2, $(\bigcup\limits_{i=1}^n$A$_i^c)^c$ = $\bigcap\limits_{i=1}^n$A$_i$ $\in$ $F$.
\end{proof}

\subsubsection{Proposition 2}
A, B $\in$ $F$, then A$\setminus$B = A - B $\in$ $F$.\medskip

\begin{proof}
    If B $\in$ $F$, then B$^c$ $\in$ $F$ by  property 2. So, A $\cap$ B$^c$ = A$\setminus$B $\in$ $F$ (As seen in proposition 1).
\end{proof}
\subsection{Probability Measure}
The probability measure P is a function returning an event's probability. A probability is a real number between zero and one.
$$ P:F\rightarrow [0,1]$$

P has to satisfy the following 3 axioms:
\begin{itemize}
    \item $P(E) \geq 0$
    \item $P(S)=1$
    \item If $E_1,E_2 \cdots \in F$ such that $E_i \cap E_j =\phi$ then:
    $$ P(\bigcup_{i=1}^{\infty} E_{i})= \sum_{i=1}^{\infty} P(E_i)$$
\end{itemize}

For two disjoint sets:
$P(E_1 \cup E_2)= P(E_1)+P(E_2)+ \sum P(\phi)$

We will later see that $P(\phi)$ is indeed 0.

\subsection{Derived Properties of Probability}
\begin{enumerate}
    \item $$P(E^C)=1-P(E)$$
        \begin{proof}
            $$E \cup E^C = S$$
                $$P(E)+P(E^C)=1$$

        \end{proof}
    \item For any two events $E_1$ and $E_2$,
    $$ P(E_1 \cup E_2)= P(E_1)+P(E_2)-P(E_1 \cap E_2)$$
    \begin{proof}
        $$ P(E_1 \cup E_2)=P(E_1)+P(E_2 \cap E_1^C)$$
        Now, $$ E_2=(E_2 \cap E_1)\cup (E_2 \cap E_1^C)$$
        $$ \Rightarrow P(E_2)=P(E_1 \cap E_2)+ P(E_1^C \cap E_2)$$
        Also,
        $$ P(E_1 \cup E_2)= P(E_1)+P(E_1^C \cap E_2)$$
        Substitute the required value in the final equation.
    \end{proof}
\end{enumerate}

Question:
$ S=\{1,2,3,4,5,6\}$. 1 and 5 are equally likely and probability of getting a 6 is one-third.

Find minimum and maximum probability that we get an even number.

Answer:$$ Minimum \;Prob. = \frac{1}{3} \;\; when \;\; P_2 = P_4 = 0$$
$$ Maximum \;Prob. = 1,  \;\; P_2+P_4 =\frac{2}{3}  $$

%31/05 notes

\section{Conditional Property}

Given that an event $A$ has occured.

$ (S,F,P) \rightarrow$ Original probability space

If additional info has been given that A has occured, probability space need to be suitably modified.

eg: $S=\{1,2,3,4,5,6\},\;E_1=\{1,2\},\;E_2=\{3,4\}$
$$ F=\{\phi , S, E_1 , E_{1}^{C},E_2 , E_{2}^{C},E_1 \cup E_2 , (E_{1} \cup E_{2})^{C}\}$$
and event $A=E_1^c = \{3,4,5,6\}$ has occured.

Then, $ F_A= \{ \phi, A, \{3,4\},\{5,6\} \} $.(shown later)


\subsection{Modified probability space}

Then,
\begin{itemize}
    \item $S_A = A$. (Modified Sample Space)

    \item $F_A = \{ (E \cap A) | E \in F \} \rightarrow E \cap A \in F$. (Modified Event Space)

    (Also if some event $C \cap A = \phi $, then $C$ won't occur)



    To prove: $F_A$ also satisfies event space axioms.(see sec. 1.4.1)

    \begin{enumerate}
        \item $A \in F_A \rightarrow S\cap A = A$(S was original sample space)
        $\Rightarrow A \in F_A$

        \item $D \in F_A \Rightarrow D = E \cap A, D^c \in F_A$

        As,

        $D^c = A \setminus D= E^c \cap A \in F \quad(Because\;  E^c \in F)$

        \item $$D_1,D_2,\cdots \in F_A$$
        $$ (E_1 \cap A), \cdots \in F_A$$
        $$ E_1, E_2 \cdots \in F$$
        $$  \Rightarrow \bigcup_{i=1}^{\infty} E_i \in F_A$$
        $$ \Rightarrow  (\bigcup_{i=1}^{\infty} E_i) \cap A \in F_A$$
        $$\Rightarrow  (\bigcup_{i=1}^{\infty} E_i \cap A) \in F_A \Rightarrow  \bigcup_{i=1}^{\infty} D_i \in F_A$$

    \end{enumerate}
    Hence, $F_A$ is an event space.

    \item Modified probability measure

    $$ P(E/A)= \frac{P(E \cap A)}{P(A)}$$

    This definition is called conditional probability measure for any $E \in F$.

    eg:
    $ F_A = \{ \phi, \{3,4,5,6\}, \{ 3,4\}, \{5,6\} \}$, then $P(\{ 3,4\} / \{3,4,5,6\})=1/2$

    Now, we need to prove $ P(E/A)$  satisfies the 3 axioms of probability measure.(see sec. 1.5)
    \begin{itemize}
        \item $ P(E/A) \geq 0$ (as ratio of two nos. which are positive)
        \item $ P(S/A)=1$
        \item $ B_1, B_2 \cdots$ are all mutually disjoint.
        $$ P(\bigcap_{i=1}^{\infty} B_i /A) = \frac{ P(\bigcup_{i=1}^{\infty} B_i \cap A)}{P(A)}$$
        $$ =\frac{\sum_{i=1}^{\infty} P(B_i \cap A)}{P(A)} = \sum_{i=1}^{\infty} P(B_i /A)$$
        $$  \Rightarrow P(\bigcap_{i=1}^{\infty} B_i /A) = \sum_{i=1}^{\infty} P(B_i /A)$$
    \end{itemize}
\end{itemize}





\section{Total probability theorem}

Events $A_1,\cdots, A_n \in F$ which are all mutually exclusive/disjoint and exhaustive. Then,
$$ A_i \cap A_j = \phi \quad \forall\; i,j$$
$$ \bigcup_{i=1}^{n} A_i =S$$

$$ P(B)= \sum_{i=1}^{n} P(B/A_i)P(A_i)$$

the total probability theorem expresses $ P(B)$  in terms of conditional probability $ P(B/A_i) $ \& prior probability $P(A_i)$
\begin{proof}

    $$ B= \bigcup_{i=1}^{n} (B \cap A_i)$$

    $A_i$'s are disjoint, so $(B \cap A_i)$ are also disjoint.

    $$ P(B)= \sum_{i=1}^{n} P(B \cap A_i)=\sum_{i=1}^{n} P(B / A_i)P(A_i)$$


\end{proof}

\subsection{Question}
Two factories manufacture zoggles. 20\% of $F_1$ are defective. 5\% of $F_2$ are defective.

In any week, $F_1$ produces twice the number of zoggles as $F_2$. What is the probability that a zoggle chosen randomly in a week is defective?

$$ P(D)=P(F_1)P(D/F_1)+P(F_2)P(D/F_2)$$
$$ = \frac{2}{3} \times \frac{1}{5} + \frac{1}{3} \times \frac{1}{20} = \frac{3}{20}$$

%2/6

\section{Bayes Theorem}
$A_1, \cdots, A_n $ are events which are mutually exclusive and exhaustive.
$B$ be an arbitrary event. Then,
$$ P(A_i/B)= \frac{P(B/A_i)P(A_i)}{\sum_{i=1}^n P(B/A_i)P(A_i)}$$

\begin{itemize}
    \item $P(A_i)$- Prior probability
    \item $P(B/A_i)$- Likelihood
    \item $P(A_i/B)$- Posterior probability
\end{itemize}

Bayes theorem expresses posterior probabilities $P(A_i/B)$ in terms of prior probabilities  $P(A_i)$ and likehoods  $P(B/A_i)$.

In some experiments $P(A_i)$ are all same, $P(A_i)=1/n$. Then posterior probabilities are proportional to likelyhoods:
$$ P(A_i/B)= \frac{P(B/A_i)}{\sum_{i=1}^n P(B/A_i)}$$
$$ \Rightarrow P(A_i/B) \propto P(B/A_i)$$

\begin{proof}

    $$ P(A_i/B) = \frac{P(A_i \cap B)}{P(B)}$$
    $$ P(A_i/B)= \frac{P(B/A_i)P(A_i)}{\sum_{i=1}^{n} P(B/A_i)P(A_i)}$$

\end{proof}

\subsubsection{Example}
In answering a question in a multiple choice test, a student knows the answer with probability $p$ and guesses the answer otherwise. If he/she guesses from $m$ choices, the probability of being correct is $\frac{1}{m}$. Find the conditional probability that the student knew the answer if he/ she answered correctly.

Ans: $A_1=$ knowing the answer. $A_2=$ Guessing the answer.

$B= $Answer is correct. $A_1 \subseteq B$

$P(A_1)= p, P(A_2)= 1-p, P(B/A_1)= 1, P(B/A_2)= \frac{1}{m}$

$$ P(A_1/B)= \frac{P(B/A_1)P(A_1)}{P(B/A_1)P(A_1)+ P(B/A_2)P(A_2)}$$
$$ = \frac{p}{p + (1-p)\frac{1}{m}}$$

\section{Indepedent Events}
$A \;\&\; B$ are said to be independent. If
$$ P(A \cap B) = P(A)P(B)$$

In terms of conditional probability,
$$ P(B/A)= \frac{P(A \cap B)}{P(A)} = \frac{P(A)P(B)}{P(B)} = P(B)$$

$$ \Rightarrow P(B/A) = P(B)$$

Probability of event $B$ remains same with or without conditioning on $A$. Hence, $B$ is said to be independent of $A$.
Knowledge of occurence of event $A$ does not give any information about $B$.

If $A\; \&\; B $ are independent, then
$ A \;\&\; B^c$ are also independent.

\begin{proof}
    $$ P(B^c / A)= \frac{P(B^c \cap A)}{P(A)}= \frac{P(A)- P(A \cap B)}{P(A)}= \frac{P(A)- P(A)P(B)}{P(A)} = P(B^c)$$
\end{proof}

\subsection{Important Results}
\begin{enumerate}
    \item $P(A/B)$ may be greater than, less than or equal to $P(A)$.
    \item Independent events and mututally exclusive events are different.

    Indepedence: $P(A \cap B)= P(A)P(B)$

    Mututally exclusive: $A \cap B = \phi$

    \begin{enumerate}
        \item (Indepedent but not mutually exclusive). Coin toss followed by throwing dice experiment.

        $$ S=\{ (H,1), (H,2), \cdots, (H,6), (T,1), \cdots, (T,6)\}$$
        $F=$ Power set of S (Always an event space)

        $A=\{(H,1), \cdots, (H,6) \}$, $B= \{ (H,2), (H,4), (H,6), (T,2),(T,4),(T,6)$

        $P(A)= 1/2 \; \& \; P(B)= 1/2$
        $$ P(A \cap B)= P(\{ (H,2), (H,4), (H,6)\})= \frac{3}{12}= \frac{1}{4}$$
        $$ P(A\cap B)= P(A)P(B)$$
        \item (Not independent but mutually exclusive)
        If the events are mutually exclusive $\Rightarrow$ they are not independent.

        Single Coin Toss: $A= \{H \}$, $B= \{T \}$ $\rightarrow$ Mututally exclusive.

        $P(A \cap B)= 0$, $P(A)P(B)= \frac{1}{4}$

        %Eg 3: (Not independent and not mutually exclusive) hw


    \end{enumerate}
    \end{enumerate}

\subsection{Conditionally indepedent events}

$A \; \& \: B$ are said to be conditionally indepedent given $C$ if
$$ P((A \cap B)/ C)= P(A/C)P(B/C)$$
In terms of conditional probabilities,
$$ P(B/C)= \frac{P((A\cap B )/ C)}{P(A/C)}= \frac{\frac{P(A \cap B \cap C)}{P(C)}}{\frac{P(A \cap C)}{P(C)}} = \frac{P(A\cap B\cap C)}{P(A \cap C)} = P(B/(A \cap C))$$

Indepedent Events: $P(A \cap B)= P(A)P(B)$ \& $P(B/A)= P(B)$.

Conditionally indepedent events: $P(A\cap B / C)= P(A/C)P(B/C)$ \& $P(B/(A\cap ))$

\subsubsection{Example}
Two fair coins are tossed, $S=\{HH, HT, TH, TT \}$, $A=\{HH, HT \} $, $B=\{HH, TH\} $, $C=\{HH \}$ \& $D=\{HT, TH\}$

\begin{enumerate}
    \item Are $A$ \& $B$ independent?
    $$ P(A \cap B)= P(\{HH\}) = \frac{1}{4}= P(A)P(B)$$
    \item  Are $A$ \& $B$ conditionally indepedent given $C$?
    $$ P((A \cap B) /C)= P(A/C)=P(B/C)= 1$$
    $$ P(A/C)= \frac{P(A \cap C)}{P(C)}= \frac{\frac{1}{4}}{\frac{1}{4}}= 1$$
    \item Are $A$ \& $B$ conditionally indepedent given $D$?

    $$P(A/D)= \frac{P(A\cap D)}{P(D)}= \frac{\frac{1}{4}}{\frac{1}{2}}=\frac{1}{2} $$
    $$P(B/D)= \frac{P(B\cap D)}{P(D)}= \frac{\frac{1}{4}}{\frac{1}{2}}=\frac{1}{2} $$
    $$ P(A\cap B /D)= 0$$
    Hence, they are not conditionally indepedent given $D$.
\end{enumerate}

If $A$ and $B$ are independent, it doesn't imply $A$ and $B$ will be conditionally indepedent given $C$ and vice-versa.
%4/6 notes
\subsection{Indepedence of collection of events}

Three events $A_1, A_2$ \& $A_3$ are said to be indepedent if:

$$ P(A_1 \cap A_2 \cap A_3)=P(A_1)P(A_2)P(A_3)$$
$$ P(A_1 \cap A_2)=P(A_1)P(A_2)\quad P(A_2 \cap A_3)=P(A_2)P(A_3)\quad P(A_3 \cap A_1)=P(A_3)P(A_1)$$



\subsubsection{Chain rule of Probability}
$$ P(A_1 \cap A_2 \cap A_3)=P(A_1)P(A_2/A_1)P(A_3/A_1\cap A_2)$$
$$ P(\bigcap_{i=1}^n A_i)=P(A_1) \prod_{i=2}^n P(A_i/A_1\cdots A_{i-1})$$
For independent events $A_1, A_2, A_3$.
$$P(A_1)P(A_2/A_1)P(A_3/(A_1 \cap A_2))= P(A_1)P(A_2)P(A_3)$$
$$\Rightarrow P(A_2/A_1)P(A_3/(A_1 \cap A_2))= P(A_2)P(A_3)$$

Hence, if $A_1$, $A_2$, $A_3$ are independent events, the first condition doesn't imply the other conditions.

Eg: Pair-wise independence does not imply that three events are independent.
Consider example of two coin tosses:
$S= \{HH,HT,TH,TT\}, A_1=\{HH,HT\},A_2=\{HH,TH\},A_3=\{HT,TH\}$.

$A_1$ \& $A_2$ are indepedent $P(A_1 \cap A_2)=P(A_1)P(A_2)$

$A_2$ \& $A_3$ are indepedent $P(A_3 \cap A_2)=P(A_3)P(A_2)$

$A_1$ \& $A_3$ are indepedent $P(A_1 \cap A_3)=P(A_1)P(A_3)$

$A_1$, $A_2$  \& $A_3$ are not still not independent as $P(A_1 \cap A_2 \cap A_3) \neq P(A_1)P(A_2)P(A_3)$.

\section{Continuity of Probability}
$\Omega$ is an equivalent notation for sample space.

Consider the probability space $(S,F,P)$.

$E_i \in F$. Let $E_1 \subseteq E_2 \subseteq \cdots$ be countably infinite sequence of events (increasing sequence of events).
Then $$P(\bigcup_{i=1}^{\infty} E_i)= \lim_{i \to \infty} P(E_i)$$.
$$ \bigcup_{i=1}^{\infty} E_i \in F$$
Pushing the limit from inside the probability expression to outside.

$$P(\bigcup_{i=1}^{\infty} E_i)=\lim_{i \to \infty }P(E_i)$$
$$P(\lim_{n \to \infty} \bigcup_{i=1}^{n}E_i)=\lim_{i \to \infty }P(E_i)$$

Exchanging limits with probability $\rightarrow$ non trivial operation.
Exchanging limits with differentiation, integration etc. $\rightarrow$ require a proof.

\begin{itemize}
    \item $$E_1 \subseteq E_2 \subseteq \cdots$$
    $$P(\bigcup_{i=1}^{\infty} E_i)= \lim_{i \to \infty} P(E_i)$$

    \begin{proof}
        We shall use the third axiom.
        $D_1, D_2 \cdots \rightarrow$ mutually exclusive events.

        $$ P(\bigcup_{i=1}^{\infty} D_i)= \sum_{i=1}^{\infty}P(D_i)$$

        $E_1 \subseteq E_2 \subseteq \rightarrow $ not mutually exclusive.

        Hence we construct a sequence which are mututally exclusive and unions of both sequences have to be the same.

        $A_1=E_1$, $A_2=E_2\setminus E_1$, $ A_3=E_3 \setminus E_2$ , $\cdots$.
        $$ P(\bigcup_{i=1}^{\infty} E_i)= P(\bigcup_{i=1}^{\infty} A_i)= \sum_{i=1}^{\infty}P(A_i)= \lim_{n \to \infty} \sum_{i=1}^{\infty}P(A_i)$$

        $$\Rightarrow \lim_{n \to \infty} \sum_{i=1}^{n} P(A_i)= \lim_{n \to \infty} P(\bigcup_{i=1}^{n}A_i)= \lim_{n \to \infty}P(E_n)$$
        If there exists a subsequence of events, which is increasing.

    \end{proof}

    \item Let $E_1 \supseteq E_2 \supseteq \cdots$ be a countably infinte sequence of events(decreasing sequence of events)

    $$P(\bigcap_{i=1}^{\infty}E_i)=\lim_{i \to \infty} P(E_i)$$

    \begin{proof}
        We can use the result of the previous proof.
        $$ E_1^c \subseteq E_2^c \subseteq \cdots$$
        which is an increasing set of events
        $$P(\bigcup_{i=1}^{\infty} E_i^c)= \lim_{i \to \infty}P(E_i^c)$$
        as,
        $$ \left(\bigcap_{i=1}^{\infty} E_i \right)= \left( \bigcup_{i=1}^{\infty} E_i^c \right)^c $$

        $$\Rightarrow 1- P(\bigcup_{i=1}^{\infty} E_i^c)= \lim_{i \to \infty}1- P(E_i^c)$$

        $$P \left(\bigcap_{i=1}^{\infty} E_i \right) = \lim_{i \to \infty }P(E_i)$$

    \end{proof}

\end{itemize}

%4/6  \subsection{Example of continuity of probability}

%7/6 lecture 6

\section{Random Variables}

Consider a probability space $(S,F,P)$ and an experiment is conducted.

Probability spaces vary a lot based on the experiment. We use random variables to be able to develop a theory of probability which is indepedent of the actual experiment which is performed.

$$S \xrightarrow[]{\text{R.V.}} \mathbb{R}$$
$$F \xrightarrow[]{\text{R.V.}} B$$

Random Variable is a function which maps the sample space to the real line.
It also maps the event space to the Borel $\sigma$-algebra, $B$.

\subsection{Borel $\sigma$-algebra}
It is the smallest $\sigma$- algebra which contains sets of the form $(-\infty ,x]\; \forall x \in \; \mathbb{R}$.

$$ B=\{ \mathbb{R} , (-\infty ,x] ,(x,\infty ), \phi, (-\infty,x) ,(x,y),[x,y], \{x\},(x,y],[x,y)\}$$

$$ E_i =(-\infty ,x_i] \quad x_i = x-\frac{1}{i}$$
$$ \bigcup_{i=1}^{\infty}(-\infty ,x_i] = \bigcup_{i=1}^{\infty} E_i =(-\infty ,x)$$


Random Variable $X:S \rightarrow R$

$X$ has to be a measurable function.

A function is said to be measurable if  pre-image of $(-\infty ,x ] \; \forall x \in \mathbb{R}$ is in the event space.
$$X:S \rightarrow R$$
$$\text{inverse image} \leftarrow(-\infty ,x ] $$
$$ X^{-1} ((-\infty ,x ]) \subseteq S \qquad  X^{-1} ((-\infty ,x ]) \in F$$
eg:
$ X: \{1,2,3,4,5,6\} \rightarrow \{0,1,0,1,0,1 \}$

$$X^-1\left( (-\infty, 0.5]\right)=\{1,3,5\}$$

In the above example, $X$ is not an invertible mapping. We are using $X^{-1}$ as a notation.

$X$ is a map from $S$ to $\mathbb{R}$ such that
$$X:S \rightarrow \mathbb{R}$$
$$ X^{-1}\left( (-\infty, x ]\right) \leftarrow (-\infty, x ] \qquad X^{-1}\left( (-\infty, x ]\right) \in F $$

\subsection{Examples}
\begin{itemize}
    \item X which is a random variable.

    $S= \{a,b,c\}\; ,\; F=\{ \phi, \{ a\}, \{b,c \}, S\}\; , \; X:S \rightarrow \mathbb{R}$

    $X(\omega) =0\; ,\; \omega =a $

    $X(\omega)= 1\;,\; \omega = b,c$
    \begin{enumerate}
        \item $( -\infty,x]\;,\; x < 0\;,\; X^{-1}\left( (-\infty , x]\right) = \phi \in F$
        \item $( -\infty,x]\;,\; 0 \leq x <1 \;,\; X^{-1}\left( (-\infty , x]\right) = \phi \in F$
        \item $( -\infty,x]\;,\; x \geq 1\;,\; X^{-1}\left( (-\infty , x]\right) = S \in F$
    \end{enumerate}

    \item X which is not a random variable
    $S= \{a,b,c\}\; ,\; F=\{ \phi, \{ a\}, \{b,c \}, S\}\; , \; X:S \rightarrow \mathbb{R}$

    $X(\omega) =0\; ,\; \omega =b $

    $X(\omega)= 1\;,\; \omega = a,c$

    But $X^{-1}((-\infty,x])\; , \;0\leq x<1 = \{b\} \; , \; \{ b\} \notin F$

    $X$ is not a random variable.
\end{itemize}

If $S$ is finite \& $F$ is a power set of $S$, then every function is a random variable.
$$ X^{-1}((-\infty,x]) \subseteq S$$

$F$ is set of all subsets of $S$.

%9/6
\subsection{Conditions on random variable}
\begin{theorem}
    Let a probability space be $(S,F,P)$ and $X$ is a random variable $X: S \rightarrow \mathbb{R}$.
    The following conditions hold:
    \begin{itemize}
        \item $X^{-1}((-\infty,x)) \in F$
        \item $X^{-1} (\{x\}) \in F$
        \item $X^{-1}((x_1 , x_2]) \in F$
        \item $X^{-1} ((x_1,x_2)) \in F$
    \end{itemize}
\end{theorem}

\begin{proof}

    Applying the axioms of the event space we want to show the above conditions are true.

    $A_i=X^{-1}((-\infty,x]) \qquad x_i = x - \frac{1}{i}$. Now,
    $$ \bigcup_{i=1}^{\infty} (-\infty,x_i] = (-\infty,x)$$

    $$ \bigcup_{i=1}^{\infty} A_i = \bigcup_{i=1}^{\infty} X^{-1}((-\infty,x_i]) = X^{-1}((-\infty,x)) \in F$$

    $$ X^{-1}((-\infty ,x] \cap {(-\infty,x)}^c) = X^{-1} (\{x\}) \in F$$

    Similarly the other conditions can also be proved.
\end{proof}

\section{Cumulative distribution function}
It is denoted by $F_X(x)$.

$$ F_X(x)= P(X \leq x) = P((-\infty, x])= P(X^{-1}((-\infty, x]))$$

The above definitions are different notations used, the last one is well defined from the probability space.

\subsection{Properties of CDF}

\begin{enumerate}
    \item $F_X(x)$ is a monotonically non-decreasing function of x.
    \begin{proof}
        If $x_2 \geq x_1$, then $F_X(x_2) \geq F_X(x_1)$.

        $$F_X(x_2) = P(X \leq x_2)= P(X \leq x_1)+P(x_1 < X \leq x_2)$$
        $$F_X(x_2) = P(X \leq x_2) \geq P(X \leq x_1) -F_X(x_1) $$

    \end{proof}

    \item $\lim_{x \to \infty} F_X(x)= 1$

    \begin{proof}
        Construct a decreasing set of events. $A_i= (-\infty, i]$, $B_i = X^{-1}(A_i)$.
        $$ \bigcap_{i=1}^{\infty}A_i= \mathbb{R}$$
        $$ \bigcap_{i=1}^{\infty}B_i= S $$

        Applying continuity of probability,
        $$ \lim_{i \to \infty}P(B_i)= P(\bigcup_{i=1}^{\infty}B_i) =P(S) = 0$$
        $$ \lim_{i \to \infty}P(X \leq i)= \lim_{x \to \infty}P(X \leq x) = \lim_{x \to \infty} F_X(x)$$

        The change from integers to real numbers $x$ in the last step is valid.

    \end{proof}
    \item $\lim_{x \to -\infty} F_X(x)= 0$
    \begin{proof}
        Construct a decreasing set of events. $A_i= (-\infty, -i]$, $B_i = X^{-1}(A_i)$.
       $$ B_1 \supseteq B_2 \supseteq \cdots$$

       $$ \bigcap_{i=1}^{\infty}B_i= \phi $$
       $$ P(\bigcap_{i=1}^{\infty}B_i) = \lim_{i \to \infty}P(B_i)= 0$$
       $$  \lim_{i \to \infty}P(B_i) =  \lim_{i \to \infty}P((-\infty,i])= \lim_{x \to \infty}P((-\infty,x]) \rightarrow \text{(x = all real nos.)}$$
       $$ \lim_{x \to \infty}P((-\infty,x]) = \lim_{x \to \infty}F_X(x)= 0$$
    \end{proof}
%11/6
    \item $F_X(x)$ is a right continuous function.
    $$ \lim_{x \to x_0^+} F_X(x)= F_X(x_0)$$

    Right continuous function: $\lim_{x \to x_0^+} f(x)= f(x_0)$

    Left continuous function: $\lim_{x \to x_0^-} f(x)= f(x_0)$

    Continuous function(Approaching from either left or right): $\lim_{x \to x_0} f(x)= f(x_0)$

    \begin{proof}
        Decreasing sequence of events $B_i= (X \leq x+\frac{1}{i})$

        $$ B_1 \supseteq B_2 \supseteq \cdots$$
        $$ \bigcap_{i=1}^{\infty}B_i= \{ X \leq x\}$$
        $$ P(\bigcap_{i=1}^{\infty}B_i) = P(X \leq x) = F_X(x)$$
        $$ \Rightarrow \lim_{i \to \infty}P(B_i)= \lim_{i \to \infty}P(X \leq x + \frac{1}{i})$$
        We are changing the variable from an integer to real.
        $$= \lim_{\epsilon \to 0}P(X \leq x + \epsilon)=\lim_{\epsilon \to 0^+}F_X(x + \epsilon) $$
        $$ = \lim_{x_0 \to x^+}F_X(x_0) \quad \text{Change of variable: }x_0= x+ \epsilon $$

    \end{proof}
\end{enumerate}

\subsection{Indicator Random Variable}
\begin{equation*}
    I_A (x)=
    \begin{cases}
      1, & \text{if}\ x \in A \\
      0, & \text{if}\ x \notin A
    \end{cases}
\end{equation*}

$$I_A:S \to \mathbb{R}$$

$$ F_{I_{A}} (x)= P(I_A \leq x)$$

If $x < 0 $, $P(I_A \leq x)= 0$.

If $0 \leq x <1 $, $P(I_A \leq x)= P(A^c)=1-P(A)$.

If $x \geq 1 $, $P(I_A \leq x)= 1$.

$$ \lim_{x \to 0^+} F_{I_A}(x)= P(A^c) \qquad F_{I_A}(0)= P(A^c)$$

$$ \lim_{x \to 1^+} F_{I_A}(x)= 1 \qquad F_{I_A}(1)= 1$$

\subsection{Examples of CDF's and non-CDF's}
\begin{itemize}
    \item Is $F_1(x)$ a valid CDF?
    \begin{equation*}
        F_1 (x)=
        \begin{cases}
          1, & \text{if}\ x \leq 0 \\
          0.5, & \text{if}\ 0<x\leq 1 \\
          0.25+0.25x, & \text{if}\ 1<x\leq 3 \\
          1, & \text{if}\ 3<x
        \end{cases}
    \end{equation*}

    No, as it is not right continuous at $x=0$.

    $$ \lim_{x=0^+}F_1(x)=0.5, \quad F_1(0)=0$$

    \item Is $F_2(x)$ a valid CDF?
    \begin{equation*}
        F_2 (x)=
        \begin{cases}
          0, & \text{if}\ x < 0 \\
          0.5, & \text{if}\ 0\leq x < 1 \\
          0.75, & \text{if}\ 1\leq x < 3 \\
          1, & \text{if}\ 3\leq x
        \end{cases}
    \end{equation*}
    It is valid as it satisfies all 4 properties.

    \item Is $F_3(x)$ a valid CDF?
    \begin{equation*}
        F_3 (x)=
        \begin{cases}
          1, & \text{if}\ x < 0 \\
          0.5, & \text{if}\ 0 \leq x < 1 \\
          0.25, & \text{if}\ 1\leq x < 3 \\
          1, & \text{if}\ 3 \leq x
        \end{cases}
    \end{equation*}
    $F_3(x)$ is not a valid CDF as it is not non-decreasing.

\end{itemize}

%14/6
\begin{lemma}
    For any $x \in \mathbb{R}$,
    $$ P(X=x)= P(X \leq x)- P(X <x)$$
    $$ P(X=x)= F_X(x)- \lim_{\epsilon \to 0}F_X(x- \epsilon)$$

\end{lemma}

Upon applying continuity of probability.

\begin{proof}
    $$ B_1 \subseteq B_2 \subseteq \cdots$$
    $$B_i=\{ X \leq x - \frac{1}{i}\} \qquad \bigcup_{i=1}^{\infty}B_i=\{ X<x\}$$

    $$ P(X<x)= P(\bigcup_{i=1}^{\infty}B_i)= \lim_{i \to \infty} B_i = \lim_{\epsilon \to \infty}P(X \leq x- \epsilon)= \lim_{\epsilon \to 0}F_X(x-\epsilon)$$
\end{proof}
\begin{corollary}
    $F_X(.)$ is left continuous if and only if $P(X=x)=0 \; \forall \; x \in \mathbb{R} $. From lemma,

    $$ P(X=x)= F_X(x)- \lim_{\epsilon \to 0^+ }F_X(x-\epsilon)$$

\end{corollary}

A function is left continuous if

$$  \lim_{\epsilon \to 0^+}F_X(x - \epsilon)= F_X(x) \quad \forall x \in \mathbb{R}$$
$$ \Rightarrow P(X=x)= 0 \quad \forall x \in \mathbb{R}$$

$F_X(.)$ is continuous, means that it is both right continuous, and in particular, left continuous.

\section{Types of Random Variables}
\begin{itemize}
    \item Continuous random variable
    \item Discrete random variable
    \item Mixed random variable
\end{itemize}

\subsection{Continuous random variables}
A random variable $X$ with cummulative distribution function $F_X(.)$ is said to be a continuous random variable if $F_X(.)$ is continuous.

$P(X=x)=0 \quad \forall \; x \in \mathbb{R}$, probability of every point is zero.

An example for a continuous random variable is:
\begin{equation*}
    F_X (x)=
    \begin{cases}
      0, & \text{if}\ x < 0 \\
      x, & \text{if}\ 0 \leq x < 1 \\
      1, & \text{if}\ x\leq 1  \\
    \end{cases}
\end{equation*}

In the context of a continuous random variable, we need to ask what is the probability of intervals or unions of intervals: $ P(a \leq X \leq b)$

If $F_X(.)$ is differentiable, given that it is continuous then we can find another function for the continuous random variable.

$$ f_X(x)= \frac{dF_X(x)}{dx}$$

$f_X(x)$ is called the probability density function (pdf).
\begin{equation*}
    f_X (x)=
    \begin{cases}
      1, & \text{if}\ 0 < x < 1 \\
      0, & \text{otherwise}\
    \end{cases}
\end{equation*}

$$ F_X(a)= P(X \leq a)= \int_{-\infty}^{a}f_X(x)dx$$

$$  P(a \leq X \leq b)=F_X(b)-F_X(a) = \int_{a}^{b}f_X(x)dx$$

$$ P(x \leq X \leq x + \Delta x) \to \Delta x\text{ is very small(infintesimal)}$$
$$ P(x \leq X \leq x + \Delta x) \approx \text{area of rectangle with b=} \Delta x \;\& \text{ h= }f_X(x)$$
$$ P(x \leq X \leq x + \Delta x) \approx f_X(x) \Delta x$$

\subsubsection{Probability density function}
When is a function a valid probability density function?

Two properties of the probability density function are:
\begin{itemize}
    \item $f_X(x) \geq 0$

    As CDF is monotonically non decreasing, it's derivative is always non-negative.
    \item $ \int_{-\infty}^{\infty}f_X(x)dx= 1 \to \quad P(X \leq \infty )= F_X(\infty)=1$
\end{itemize}

Note: $f_X(.) \nleq 1$

The probability density function itself doesn't indicate any probability.
Only the area under the curve indicates probability.

\subsection{Discrete random variable}

$X$ is said to be a discrete random variable if the range of $X$ is either finite or countably infinite in $\mathbb{R}$.
$$ X:S \to \mathbb{R}$$

CDF of a discrete random variable will be constant everywhere and jumps at some points(finite or countably infinite number of points).

Range of $X={x_1,x_2,\cdots}$

Discrete random variables can take non-zero values unlike the continuous r.v's.

$$ F_X(a)= \sum_{x_i \leq a}P(X= x_i)$$

$$ P(X=x_i)= P_X(x_i)\qquad x_i \text{ is in the range of X.}$$
$P_X$ is said to be the probability mass function.

\subsubsection{Probability mass function}
When is a function a valid probability mass function?
$$ S= \text{ Range of X }= \{ x_1, x_2, \cdots\}$$
Two properties of the probability mass function are:
\begin{itemize}
    \item $P_X(x_i) \geq 0$

    \item $ \sum_{x_i \in S}P_X(x_i)=1$
\end{itemize}
%17/6

\subsection{Mixed random variable}

$F_X(.)$ is continuous in some intervals and also jumps at some points. The probability density function has some impulses included in it. Let, $X_1$ be a continuous random variable, $X_2$ be a discrete random variable, then $Y$, a linear combination, is a mixed variable.
$$ Y= \alpha X_1 +\beta X_2$$

\subsection{Functions of random variables}
$X$ is a random variable. $X: S \to \mathbb{R}$.

$$ Y=g(X) \qquad g:\mathbb{R} \to \mathbb{R} \qquad Y= goX:S\to \mathbb{R}$$

We require a condition on $g$ to find out when $Y$ is a random variable.
$$ Y^{-1}((-\infty ,y]) \in F \Rightarrow X^{-1} \left( g^{-1} ((-\infty,y])\right) \in F$$
Let $\mathfrak{B}$ be an arbitrary set in the Borel $\sigma$-algebra generated by intervals of the form $(-\infty,x] = \mathfrak{B}$.

Then, since $X$ is a random variable, $X^{-1}(\mathfrak{B}) \in F$.

$ g^{-1} ((-\infty,y]) \in \mathfrak{B}$, (Borel $\sigma$-algebra generated by intervals of the form $(-\infty,x] $).
$$X^{-1} \left( g^{-1} ((-\infty,y])\right) \in F \Rightarrow \text{Y is a random variable} $$

Any common functions satisfy the condition needed for $g$.

\begin{itemize}
    \item
    Suppose $X$ is a discrete random variable, $X: S \to \mathbb{R}$, range of $X$ is discrete.

    $g$ is a function, such that $Y=g(X)$. Then $Y$ is a discrete random variable.

    $X$ has a probability mass function $P_X$, $Y \to P_Y$. Then,
    \begin{align*}
        P_Y(y)&= P(Y=y)= P(g(X)=y) \\
        &= P(\{ x_i | g(x_i)=y\}) \\
        &= \sum_{x_i : g(x_i)=y} P_X(x_i)
    \end{align*}

    Eg: Tossing a coin till first head.

    $$ S= \{ H,TH,TTH, \cdots\}$$

    $$X:S \to \mathbb{R}\qquad H \to 1 \qquad TH \to 2 \qquad TTH \to 3 \cdots$$

    $Y=g(X)= X \text{ mod } 4 \Rightarrow \text{Range of Y}= \{ 0,1,2,3\}$

    $$P_Y(0)= P(Y=0)= P(X \text{ mod } 4 =0)= P(\{ 4,8,\cdots\})= \sum_{x \text{ mod } 4=0}P_X(x)$$

    \item $X$ is a continuous random variable, $Y= g(X)$.

    Based on $g$, it can either be continuous or discrete.

    \begin{enumerate}
        \item When $X$ is continuous \& $Y$ is also continuous.

        Let $F_X(.)$ be the CDF of $X$ and $f_X(.)$ be the PDF of $Y$.
        $$ Y= aX+b \qquad a,b \in \mathbb{R}$$
        For the CDF's:
            $$F_Y(y)= P(Y \leq y) $$

        $$ \{ Y \leq y\}= \{ aX+b \leq Y\}$$
        \begin{enumerate}
            \item If $a>0$,
            $$ \{ Y \leq y\}  = \{ X \leq \frac{y-b}{a}\}$$
            $$ F_Y(y)= P(Y \leq y)= P\left( X \leq \frac{y-b}{a}\right)= F_X\left( \frac{y-b}{a}\right)$$
            \item If $a<0$,
            $$ \{ Y \leq y\}  = \{ X \geq \frac{y-b}{a}\}$$
            $$ F_Y(y)= P(Y \leq y)= P\left( X \geq \frac{y-b}{a}\right)= 1-F_X\left( \frac{y-b}{a}\right)$$
        \end{enumerate}

        For the PDF's:
        \begin{enumerate}
            \item If $a>0$

            $$ F_Y(y)= F_X\left( \frac{y-b}{a}\right)$$
            \begin{align*}
                f_Y(y)= \frac{dF_Y(y)}{dy} &= \frac{d}{dy}F_X\left( \frac{y-b}{a} \right)\\
                &= f_X \left( \frac{y-b}{a} \right)\frac{d}{dy}\left(\frac{y-b}{a} \right) \\
                &= \frac{1}{a}f_X\left(\frac{y-b}{a} \right)
            \end{align*}

            \item If $a>0$

            $$ F_Y(y)= 1- F_X\left( \frac{y-b}{a} \right)$$
            \begin{align*}
                f_Y(y)= \frac{-1}{a}f_X\left(\frac{y-b}{a} \right)
            \end{align*}


        \end{enumerate}

        Hence,
        \fbox{$ f_Y(y)= \frac{1}{|a|}f_X \left(\frac{y-b}{a} \right)$}
%18/6
        \item $X$ is continuous and $Y$ is continuous, but a many to one function.
        $$ Y= X^2$$
        Now let us find the CDF \& PDF of $Y$ in therms of CDF \& PDF of $X$.
        \begin{enumerate}
            \item $y<0$, $F_Y(y)=0$
            \item $y \geq 0$,
            \begin{align*}
                F_Y(y)= &= P(Y \leq y) \\
                    &= P(X^2 \leq y) = P(-\sqrt{y} \leq x \leq \sqrt{y}) \\
                    &= F_X(\sqrt{y})- F_X(-\sqrt{y}) + P(x= -\sqrt{y}) \\
                    &= F_X(\sqrt{y})- F_X(-\sqrt{y})
            \end{align*}
        \end{enumerate}

        $$ f_Y(y)= \frac{dF_Y(y)}{dy}= \frac{d}{dy}(F_X(\sqrt{y})- F_X(-\sqrt{y}))$$
        $$ = \frac{1}{2\sqrt{y}}[f_X(\sqrt{y})- f_X(-\sqrt{y})]$$
        \item $X$ is continuous, $Y$ is continuous and a many to one function.
        \begin{equation*}
            f_X (x)=
            \begin{cases}
              \frac{1}{2\pi}, & \text{if}\ 0 \leq x \leq 2\pi \\
              0, & \text{otherwise}\
            \end{cases}
        \end{equation*}
        $$ F_X(x)= \int_{-\infty}^{x} f_x(x)dx$$
        $$ Y=\sin X$$
        Let us find the PDF of $Y$.

        \begin{enumerate}
            \item Consider $0 \leq y \leq 1$
            \begin{align*}
                F_Y(y)&= P(Y \leq y) \\
                    &= P(\sin{X} \leq Y) \\
                    &= P(\{ 0 \leq X \leq \sin^{-1} y\} \cup \{ \pi - \sin^{-1}y \leq X \leq 2\pi \})\\
                    &=P( 0 \leq X \leq \sin^{-1}y)+(\pi - \sin^{-1}y \leq X \leq 2 \pi )\\
                    &= F_X(\sin^{-1}y)- F_X(0)+F_X(2\pi)- F_X(\pi - \sin^{-1}y)\\
                    &= \frac{\sin^{-1}y}{2\pi}-0+1- \left( \frac{\pi - \sin^{-1}y}{2\pi}\right) \\
                    &= \frac{1}{2}+ \frac{\sin^{-1}y}{\pi}
            \end{align*}
            \item $-1 \leq y <0$
            \begin{align*}
                F_y(y)&= P(Y \leq y) = P(\sin X \leq y)\\
                &= P(\pi - \sin^{-1}y \leq X \leq 2\pi + \sin^{-1}y )
            \end{align*}
        \end{enumerate}

    %    \begin{equation*}
    %        f_Y (y)=
    %        \begin{cases}
    %         \frac{1}{\pi \sqrt{1-y^2}}, & \text{if}\ -1 \leq y < 1 \\
    %         \frac{1}{\pi \sqrt{1-y^2}}, & \text{if}\ 0 \leq y \leq 1
    %
    %        \end{cases}
    %    \end{equation*}

    \item $X$ is continuous and $Y$ is discrete.

    $X$ has CDF $F_X(.)$ \& PDF $f_X(.)$

    $Y$ has CDF $F_Y(.)$ \& PMF $P_Y(.)$

    $$Y=g(x)=k \; if \; k \leq x < k+1 \qquad k \in \mathbb{Z} $$
    The above operation is also called quantization. Range of $g$ is countably infinite \& thus $Y$ is a discrete random variable.

    We would like to experss the PMF of $Y$ in terms of the PDF of $X$.


    \begin{align*}
        P_Y(y)&= P(Y=y)= P(y \leq X < y+1) \\
        &= \int_{y}^{y+1}f_X(x)dx
    \end{align*}

    In general,
    $$ P_Y(y)= \int f_X(x)dx \qquad S= \{ x: g(x)=y\}$$

    \end{enumerate}
\end{itemize}

    \subsection{General formula for determining PDF of $Y= g(X)$}
    Where $g$ is differentiable,

    $$ P(y \leq Y \leq y + \Delta y) \approx f_Y(y)\Delta y$$
    The left hand side can be written in terms of PDF of $X$.
    $$ g(x_i)= y$$
    $$ g^{-1}[y,y + \Delta y]= [x_1, x_1+ \Delta x_1]\cup [x_2, x_2+ \Delta x_2] \cdots [x_n, x_n+ \Delta x_n]$$
What is the sign of slope of $g(x)$ at $x_i$?
\begin{itemize}
    \item If $g^{'} (x_i) \geq 0 \qquad [x_i,x_i+ \delta x_i]$
    \item If $g^{'} (x_i) < 0 \qquad [x_i- \delta x_i,x_i]$
\end{itemize}

\begin{align*}
    f_Y(y)\Delta y &= \sum_{i=1}^{n}P(x_i \leq X \leq x_i + \Delta x_i)\\
                    &= \sum_{i=1}^{n} f_x(x_i)\Delta x_i
\end{align*}
$$ f_Y(y)= \sum_{i=1}^{n} f_X(x_i)\frac{\Delta x_i}{\Delta y}= \sum_{i=1}^{n} f_X(x_i)\frac{1}{(\Delta y / \Delta x_i)}$$

For infintesimally small $\Delta y$ \& corresponding $\Delta x_i$:
$$ \frac{\Delta y}{\Delta x_i}= |g^{'}(x_i)|$$

We take modulus as LHS is positive, i.e. magnitude of the slope of tangent at $x_i$.

$$ f_Y(y) = \sum_{i=1}^{n} \frac{f_X(x_i)}{|g^{'}(x_i)|}$$

Examples:
\begin{itemize}
    \item $Y= X^2$
    $$ f_Y(y)= \frac{f_X(\sqrt{y})}{2\sqrt{y}}+ \frac{f_X(-\sqrt{y})}{2\sqrt{y}}$$
    \item $Y= \sin X$, we take $\sin^{-1} y(2n\pi + \sin^{-1} y)$ \& $\pi - \sin^{-1} y(2n\pi + \pi - \sin^{-1} y)$

    $$ f_Y(y)= \sum_{n}\left[ \frac{f_X(2n\pi + \sin^{-1} y)}{\sqrt{1- y^2}} + \frac{f_X(2n\pi + \pi - \sin^{-1} y)}{\sqrt{1- y^2}} \right]$$
\end{itemize}

%21/6

\begin{theorem}
    If $Y= F_X(X)$, where $X$ itself is a random variable with CDF $F_X(.)$, the CDF of Y:
    $$ F_Y(y)= P(Y \leq y)= P(F_X(x) \leq y)$$
\end{theorem}
    \begin{itemize}
        \item If $y<0$,
        $$ \{ X \leq F_{X}^{-1}((-\infty,y])\}= \phi \qquad P(F_{X}(x)\leq y)=0 $$
        \item If $y \geq 1$,
        \begin{align*}
            F_Y(y)&= P(Y \leq y) = P(F_X(x) \leq y) \\
            &= 1 \qquad \text{(max value of }F_X \text{ is 1, } F_{X}^{-1}((-\infty,y])= \mathbb{R})
        \end{align*}
        \item If $0 \leq y <1 $,
        \begin{align*}
            F_Y(y)= P(Y \leq y)&= P(F_X(x)\leq y) \\
            &= P(X \leq F_{X}^{-1}(y)) \\
            &= F_X(F_{X}^{-1}(y)) \\
            &= y
        \end{align*}
    \end{itemize}
    \begin{equation*}
           f_Y (y)=
            \begin{cases}
             0, & \text{if}\  y < 0 \\
             y, & \text{if}\  0 \leq y < 1 \\
             1, & \text{if}\  y \geq 1
            \end{cases}
        \end{equation*}
If we take any random variable $X$ \& apply $F_X(.)$ as a function of $X$, then resulting random variable is a uniform random variable.

Suppose we start with an uniform random variable $Y$ and consider a function of $Y$ which is $X= F_{X}^{-1}(Y)$, then X has a CDF $F_X(.)$.

%\fbox{In, MATLAB, there is an inbuilt function }

\section{Expectation of a random variable}
It is also called mean (or average).

For a discrete random variable $X$, let $S$ be the range of $X$, which is either finite or countably infinte.

$$ E(X)= \sum_{x_i \in S}x_i P_X(x_i)$$

where $P_X$ is the PMF of random variable $X$.

The expectation, is based on the weighted average, where weights are the probabilities of the random variable taking a particular value unlike the general notion of average.

For a continuous random variable $X$,
$$ E(X)= \int_{-\infty}^{\infty}x f_X(x)dx$$
The integral can be thought of as the limit of a summation. Hence,
$$ E(X)= \lim_{\Delta x_i \to 0} \sum_{i= -\infty}^{\infty}x_i f_X(x_i) \Delta x_i$$

\subsection{Expectation of a function of a random variable}

$ Y= g(X)$, $X$ \& $Y$ are discrete.
\begin{align*}
    E(Y)= \sum_{y_i}y_i P_Y(y_i)
\end{align*}
We can express $E(Y)$ in terms of PMF of $X$, $P_X$,
\begin{align*}
    E(Y)&= \sum_{y_i}y_i P_Y(y_i) \\
    &= \sum_{y_i}y_i \sum_{x_{i,j}:g(x_{i,j})= y_i} P_X(x_{i,j}) \\
    &= \sum_{y_i} \sum_{x_{i,j}:g(x_{i,j})= y_i} y_i P_X(x_{i,j}) \\
    &= \sum_{y_i} \sum_{x_{i,j}:g(x_{i,j})= y_i} g(x_{i,j}) P_X(x_{i,j}) \\
    &= \sum_{x_j} g(x_j) P_X(x_j)\\
    \Rightarrow E(Y) &= \sum_{y_i}y_i P_Y(y_i) \\
    &= \sum_{x_i} g(x_i) P_X(x_i)
\end{align*}
For continuous random variable,
\begin{align*}
    E(Y) &= \int_{-\infty}^{\infty}y f_Y(y)dy \\
    &= \int_{-\infty}^{\infty} g(x)f_X(x)dx
\end{align*}

\subsection{Variance of a random variable}
It is defined as,
$$ E[g(X)] \qquad g(X)= (X - E(X))^2$$

$E(X)$ indicates the average value of a random variable. So there is a variation in the values the random variable takes around mean, now we would like to measure this variation and hence the variance comes into play.

$(X- E(X))$ measures variation from the mean, and we square it so that the positive and negative values don't cancel each other.


\end{document}
